{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "\n",
    "np.random.seed(42)\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "# load training datasets\n",
    "train = pd.read_csv(os.path.join('competition_data', 'train_set.csv'), parse_dates=[2,])\n",
    "tube_data = pd.read_csv(os.path.join('competition_data', 'tube.csv'))\n",
    "\n",
    "train = pd.merge(train, tube_data, on='tube_assembly_id')\n",
    "\n",
    "# create some new features\n",
    "train['year'] = train.quote_date.dt.year\n",
    "train['month'] = train.quote_date.dt.month\n",
    "train['week'] = train.quote_date.dt.dayofyear % 52\n",
    "\n",
    "train = train.drop(['quote_date', 'tube_assembly_id'], axis=1)\n",
    "rs = ShuffleSplit(train.shape[0], n_iter=3, train_size=.2, test_size=.8, random_state=0)\n",
    "for train_index, _ in rs:\n",
    "    pass\n",
    "\n",
    "train = train.iloc[train_index]\n",
    "print(train.shape)\n",
    "# Adapted from R script, only use top {threshold features from categorical columns}\n",
    "newdf = train.select_dtypes(include=numerics)\n",
    "numcolumns = newdf.columns.values\n",
    "\n",
    "allcolumns = train.columns.values\n",
    "nonnumcolumns = list(set(allcolumns) - set(numcolumns))\n",
    "print(\"Numcolumns %s \" % numcolumns)\n",
    "print(\"Nonnumcolumns %s \" % nonnumcolumns)\n",
    "\n",
    "print(\"Nans before processing: \\n {0}\".format(train.isnull().sum()))\n",
    "train[numcolumns] = train[numcolumns].fillna(-999999)\n",
    "train[nonnumcolumns] = train[nonnumcolumns].fillna(\"NAvalue\")\n",
    "print(\"Nans after processing: \\n {0}\".format(train.isnull().sum()))\n",
    "\n",
    "for col in nonnumcolumns:\n",
    "    ser = train[col]\n",
    "    counts = ser.value_counts().keys()\n",
    "    # print \"%s has %d different values before\" % (col, len(counts))\n",
    "    threshold = 5\n",
    "    if len(counts) > threshold:\n",
    "        ser[~ser.isin(counts[:threshold])] = \"rareValue\"\n",
    "    if len(counts) <= 1:\n",
    "        print(\"Dropping Column %s with %d values\" % (col, len(counts)))\n",
    "        train = train.drop(col, axis=1)\n",
    "    else:\n",
    "        train[col] = ser.astype('category')\n",
    "\n",
    "train = pd.get_dummies(train)\n",
    "print(\"Size after dummies {0}\".format(train.shape))\n",
    "\n",
    "# Use log for some variables for better visualization\n",
    "train[\"logquantity\"] = np.log(train['quantity'])\n",
    "train[\"log1usage\"] = np.log1p(train['annual_usage'])\n",
    "train[\"log1radius\"] = np.log1p(train['bend_radius'])\n",
    "train[\"log1length\"] = np.log1p(train['length'])\n",
    "train = train.drop(['quantity', 'annual_usage', 'bend_radius', 'length'], axis=1)\n",
    "\n",
    "labels = train.cost.values\n",
    "Xtrain = train.drop(['cost'], axis=1)\n",
    "names = list(Xtrain.columns.values)\n",
    "Xtrain = np.array(Xtrain)\n",
    "\n",
    "label_log = np.log1p(labels)\n",
    "Xtrain, label_log = shuffle(Xtrain, label_log, random_state=666)\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=50, max_depth=15)\n",
    "model.fit(Xtrain, label_log)\n",
    "features = []\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(len(importances)):\n",
    "    print(\"%d. feature %d (%f), %s\" % (f + 1, indices[f], importances[indices[f]], names[indices[f]]))\n",
    "    features.append(indices[f])\n",
    "    # Print only first 5 most important variables\n",
    "    if len(features) >= 5:\n",
    "        break\n",
    "\n",
    "q = pd.qcut(train[\"cost\"], 5)\n",
    "print(\"Bins are {0}\".format(q))\n",
    "train['cost_5'] = q\n",
    "\n",
    "fig = plt.figure()\n",
    "featurenames = [names[feature] for feature in features]\n",
    "featurenames.append('cost_5')\n",
    "pg = sns.pairplot(train[featurenames], hue='cost_5', size=2.5)\n",
    "pg.savefig('pairplotquintile.png')\n",
    "\n",
    "\n",
    "print(\"Training GBRT...\")\n",
    "clf = GradientBoostingRegressor(n_estimators=100, max_depth=4,\n",
    "                                learning_rate=0.1, loss='huber',\n",
    "                                random_state=1)\n",
    "clf.fit(Xtrain, label_log)\n",
    "print('Convenience plot with ``partial_dependence_plots``')\n",
    "\n",
    "# 2-D dependence plot\n",
    "target_feature = (features[0], features[1])\n",
    "features.append(target_feature)\n",
    "fig, axs = plot_partial_dependence(clf, Xtrain, features, feature_names=names,\n",
    "                                   n_jobs=3, grid_resolution=50)\n",
    "fig.savefig('partial.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
